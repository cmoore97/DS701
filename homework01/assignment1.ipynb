{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Introduction to Pandas and Scikit-Learn\n",
    "\n",
    "Pandas is a powerful data manipulation and analysis library for Python. It provides data structures like DataFrames and Series that allow for efficient handling of structured data. Pandas is particularly useful for tasks such as reading and writing data in various formats, data cleaning, merging datasets, and performing complex operations on data.\n",
    "\n",
    "Scikit-learn, on the other hand, is a machine learning library for Python. It provides a wide range of supervised and unsupervised learning algorithms, as well as tools for model selection, evaluation, and preprocessing. Scikit-learn is designed to be user-friendly and efficient, making it a popular choice for both beginners and experienced data scientists.\n",
    "\n",
    "Together, Pandas and Scikit-learn form a powerful combination for data analysis and machine learning tasks. Pandas is often used to prepare and manipulate data, which can then be fed into Scikit-learn models for training and prediction.\n",
    "\n",
    "In this assignment, we'll start with the fundamentals of data loading/manipulation in pandas, then move on to basics of scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the **Census Income** dataset which is available on the [UCI ML Dataset Page](https://archive.ics.uci.edu/dataset/20/census+income).\n",
    "\n",
    "The goal is to predict whether a person's income was greater than $50K based on 1994 census data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a quick look at the dataset. We'll use the .head() function to view the first 5 records of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt     education  educational-num      marital-status  \\\n",
       "0   25    Private  226802          11th                7       Never-married   \n",
       "1   38    Private   89814       HS-grad                9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951    Assoc-acdm               12  Married-civ-spouse   \n",
       "3   44    Private  160323  Some-college               10  Married-civ-spouse   \n",
       "4   18          ?  103497  Some-college               10       Never-married   \n",
       "\n",
       "          occupation relationship   race  gender  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
       "1    Farming-fishing      Husband  White    Male             0             0   \n",
       "2    Protective-serv      Husband  White    Male             0             0   \n",
       "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
       "4                  ?    Own-child  White  Female             0             0   \n",
       "\n",
       "   hours-per-week native-country income  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Feel free to refer to the course notes on [pandas](https://tools4ds.github.io/DS701-Course-Notes/02B-Pandas.html) for the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1a**: Write a function `get_rows_and_columns` that takes as input a CSV filename, loads this file into a Pandas dataframe, and returns a tuple of the number of rows and columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def get_rows_and_columns(file_path):\n",
    "    df = pd.read_csv('adult.csv')\n",
    "    return df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rows_and_columns('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1a</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q1a results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 1b**: Write a function `compute_missing_percentage` that converts '?' to `pd.NA` and returns the percentage of missing data (i.e., NaNs) for each column in the dataset.\n",
    "\n",
    "The term `pd.NA` is the way to represent [missing values](https://pandas.pydata.org/docs/reference/missing_value.html) (not available) in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def compute_missing_percentage(df):\n",
    "    missingPct = []\n",
    "    tot = df.shape[0]\n",
    "\n",
    "    for col in df.columns:\n",
    "        missingNo = 0\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            if str(df.loc[i, col]) == \"?\":\n",
    "                df.loc[i, col] = pd.NA\n",
    "                missingNo += 1\n",
    "        \n",
    "        missingPct.append(missingNo / tot)\n",
    "\n",
    "    output = pd.DataFrame(missingPct, columns=df.columns).T\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "15 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m     columns = \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[39m, in \u001b[36m_validate_or_indexify_columns\u001b[39m\u001b[34m(content, columns)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    987\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns passed, passed data had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    989\u001b[39m     )\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: 15 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompute_missing_percentage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcompute_missing_percentage\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     11\u001b[39m             missingNo += \u001b[32m1\u001b[39m\n\u001b[32m     13\u001b[39m     missingPct[col] = missingNo / tot\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m output = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmissingPct\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:851\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m         arrays,\n\u001b[32m    861\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         typ=manager,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    939\u001b[39m     columns = _validate_or_indexify_columns(contents, columns)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m    945\u001b[39m     contents = convert_object_array(contents, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: 15 columns passed, passed data had 2 columns"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "compute_missing_percentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q1b</pre> results:</strong></p><p><strong><pre style='display: inline;'>q1b - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1b 0\n",
       "    Failed example:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1b 0[0]>\", line 1, in <module>\n",
       "            bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
       "        TypeError: 'float' object is not subscriptable\n",
       "</pre><p><strong><pre style='display: inline;'>q1b - 2</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1b 1\n",
       "    Failed example:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1b 1[0]>\", line 1, in <module>\n",
       "            bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
       "        TypeError: 'float' object is not subscriptable\n",
       "</pre><p><strong><pre style='display: inline;'>q1b - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1b 2\n",
       "    Failed example:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1b 2[0]>\", line 1, in <module>\n",
       "            bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
       "        TypeError: 'float' object is not subscriptable\n",
       "</pre><p><strong><pre style='display: inline;'>q1b - 4</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1b 3\n",
       "    Failed example:\n",
       "        bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1b 3[0]>\", line 1, in <module>\n",
       "            bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "                            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
       "        TypeError: 'float' object is not subscriptable\n",
       "</pre><p><strong><pre style='display: inline;'>q1b - 5</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "    Expecting:\n",
       "        True\n",
       "    **********************************************************************\n",
       "    Line 1, in q1b 4\n",
       "    Failed example:\n",
       "        int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q1b 4[0]>\", line 1, in <module>\n",
       "            int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "        AttributeError: 'float' object has no attribute 'value_counts'\n",
       "</pre>"
      ],
      "text/plain": [
       "q1b results:\n",
       "    q1b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 0\n",
       "        Failed example:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1b 0[0]>\", line 1, in <module>\n",
       "                bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\n",
       "                                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^\n",
       "            TypeError: 'float' object is not subscriptable\n",
       "\n",
       "    q1b - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 1\n",
       "        Failed example:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1b 1[0]>\", line 1, in <module>\n",
       "                bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\n",
       "                                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\n",
       "            TypeError: 'float' object is not subscriptable\n",
       "\n",
       "    q1b - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 2\n",
       "        Failed example:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1b 2[0]>\", line 1, in <module>\n",
       "                bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\n",
       "                                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^\n",
       "            TypeError: 'float' object is not subscriptable\n",
       "\n",
       "    q1b - 4 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 3\n",
       "        Failed example:\n",
       "            bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1b 3[0]>\", line 1, in <module>\n",
       "                bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\n",
       "                                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
       "            TypeError: 'float' object is not subscriptable\n",
       "\n",
       "    q1b - 5 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "        Expecting:\n",
       "            True\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 4\n",
       "        Failed example:\n",
       "            int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\doctest.py\", line 1355, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q1b 4[0]>\", line 1, in <module>\n",
       "                int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\n",
       "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "            AttributeError: 'float' object has no attribute 'value_counts'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1c**: Write a function `unique_occupation` that returns the number of unique occupation present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def unique_occupation(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "unique_occupation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 1d**: Write a function `categorical_column_with_max_unique_values` that identifies and returns the index of the **column with maximum number of distinct categorical values** in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def categorical_column_with_max_unique_values(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "categorical_column_with_max_unique_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Part 2: Exploratory data analysis and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2a**: Write a function `plot_categorical_distribution` to plot the distribution of the column 'education' as a histogram.\n",
    "\n",
    "You can use Pandas `.plot()` method for this. Look at the DataFrame `.value_counts` method as well. See class examples for how to add labels and titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_categorical_distribution(df):\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_categorical_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2b**: Write a function `plot_age_hours_scatter` that creates a scatter plot of 'age' vs 'hours-per-week', coloring points by 'income'.\n",
    "\n",
    "You'll want to look at MatPlotLib's `pyplot.scatter()` for this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_age_hours_scatter(df):\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_age_hours_scatter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2c**: Write a function `plot_income_by_marital_status` which plots a stacked bar chart that shows the proportion of income levels for each 'marital-status' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def plot_income_by_marital_status(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "plot_income_by_marital_status(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Part 3: Advanced Pandas Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3a**: Write a function `education_stats` that returns a dataframe with mean 'age' and median 'hours-per-week' categorized on the 'education' level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def education_stats(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3b**: Write a function `calculate_most_popular_occupation` that returns a dataframe of the most popular occupation for each 'native-country' and order them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_most_popular_occupation(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "calculate_most_popular_occupation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 3c**: Write a function `workclass_by_income` that returns a dataframe of the top 5 workclass with the highest number of people having income >50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def workclass_by_income(df):\n",
    "     ...\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "workclass_by_income(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO RUN THIS CELL!\n",
    "\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "df_new = df.drop(columns=['native-country', 'fnlwgt']).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we'll implement [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) using scikit-learn. Logistic regression is used when trying to predict a binary outcome (0 or 1, True or False, etc.) We will go over the details of logistic regression in details later in the course. \n",
    "\n",
    "Here, we will try to predict income (>50k or <= 50k>) and follow standard ML procedures for data pre-processing. You can use scikit-learn's documentation, [the lecture notes on scikit-learn](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html) or online resources for guidance. \n",
    "\n",
    "#### From here on use the 'df_new' variable instead of 'df'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We saw in lecture that models are trained on the 'training' set and evaluated on unseen data on the 'testing' set. The dataset has 'feature' (`X_train`, `X_test`) and the 'outcome' (`y_train`, `y_test`) variables. \n",
    "\n",
    "**Question 4a:** Write a function called `split_data` that takes a dataframe as its only parameter, splits it into training and test splits and returns them. Use 20% for the testing set. \n",
    "\n",
    "Use `train_test_split` to produce the splits. Provide a `random_state` of 42 for reproducibility.\n",
    "\n",
    "`split_data` should return 4 things: X_train, X_test y_train and y_test. To do that, you need to pass in the X *and* the y (income column) to `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Question 4b**: Write a function `preprocess_data` that takes X_train, y_train, X_test, and y_test as input (the splits we created earlier!) and does the following:\n",
    "\n",
    " - Scale the *numerical* columns using sklearn's `MinMaxScaler` to the range [0,1] for both train and test sets\n",
    "  \n",
    " - Replace \"<=50K\" with 0 and \">50K\" with 1 in both y_train and y_test\n",
    "\n",
    " - One-hot encode the categorical columns for both train and test sets. Check the next cell for some hints! \n",
    "  \n",
    "The function should then return the preprocessed X_train, y_train, X_test, and y_test\n",
    "\n",
    "Refer to the material below and [sklearn course notes](https://tools4ds.github.io/DS701-Course-Notes/02C-Sklearn.html#prepare-the-dataset) for help! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One hot encoding is a way of turning textual data into numbers, so that models can work with them. \n",
    "\n",
    "Pandas has a method called `pd.get_dummies()` that can do one-hot encoding. \n",
    "\n",
    "Let's illustrate with an example.  Let's say we are describing 4 people, each\n",
    "with attribute 'Gender' and 'City' where they reside.\n",
    "\n",
    "Create a dictionary with 'City' and 'Gender' keys, each with a length 4 list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Sample DataFrame with categorical columns\n",
    "data = {'City': ['New York', 'Los Angeles', 'New York', 'Chicago'],\n",
    "        'Gender': ['Female', 'Male', 'Male', 'Female']}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can give that to Pandas `pd.DataFrame()` and it will create a DataFrame with\n",
    "a City column and a Gender column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data) \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we can call `pd.get_dummies` with the dataframe and it will convert each\n",
    "categorical column into a set of columns with each category and column entries\n",
    "of True or False (e.g. 1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['City', 'Gender'])\n",
    "# notice how I'm passing in the columns -- you should do this too! Hint: you wrote a function for this earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "print(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "   Notice how now every `City` value has its own column, and that every row with a city has a 1 for that city (row 1 in the old dataframe has New York for the `City`, and row in the new dataframe has a 1 for `City_New York`). Everywhere else you have a 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, X_test, y_train, y_test):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's get to training! Remember, we're trying to predict whether income is more then 50k (>50k), or less than or equal to (<=50k).\n",
    "\n",
    "**Question 4c:** Write a function called train_model that takes the training splits (X_train and y_train) as its parameters. \n",
    "\n",
    "- Initialize the logistic regression model\n",
    "- Fit it to our data. (Training step)\n",
    "\n",
    "At the end, return the fitted model. \n",
    "\n",
    "You can refer to [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Let's evaluate the performance of our model! \n",
    "\n",
    "**Question 4d:** Write a function called evaluate_model that takes the fitted model and `X_test`, `y_test` as parameters, runs the model on the testing features (`X_test`) and returns the *accuracy score* of the predictions against the ground truth (`y_test`). \n",
    "\n",
    "You can refer to [sklearn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Execute all cells and save the notebook before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1a": {
     "name": "q1a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_rows_and_columns('adult.csv') == (48842, 15)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['age'], 0.0))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['workclass'], 5.730724))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['occupation'], 5.751198))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(compute_missing_percentage(df)['native-country'], 1.754637))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(compute_missing_percentage(df).value_counts().get(0.0)) == 12\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> unique_occupation(df) == 15\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_occupation(df) == 13\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> unique_occupation(df) == 14\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'native-country'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'workclass'\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> categorical_column_with_max_unique_values(df) == 'occupation'\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(education_stats(df)) == 16\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> set(education_stats(df).columns) == {'education', 'age', 'hours-per-week'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(np.isclose(education_stats(df).iloc[0]['age'], 37.902808))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(education_stats(df).iloc[1]['hours-per-week'] == 40.0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> int(education_stats(df)['hours-per-week'].value_counts().get(40.0, 0)) == 14\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert education_stats(df).iloc[13]['education'] == 'Preschool'\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert education_stats(df).iloc[7]['education'] == 'Assoc-acdm'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'United-States']['occupation'].values[0] == 'Exec-managerial'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'India']['occupation'].values[0] == 'Prof-specialty'\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'England']['occupation'].values[0] == 'Craft-repair'\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> calculate_most_popular_occupation(df)[calculate_most_popular_occupation(df)['native-country'] == 'Germany']['occupation'].values[0] == 'Exec-managerial'\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Private']['count'].values[0] == 7387)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Federal-gov']['count'].values[0] == 561)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Local-gov']['count'].values[0] == 920)\nFalse",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> bool(workclass_by_income(df)[workclass_by_income(df)['workclass'] == 'Self-emp-not-inc']['count'].values[0] == 565)\nFalse",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_split_data():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     output = split_data(df_new)\n...     assert len(output) == 4, 'split_data() should return 4 things. Make sure you pass both the X and the y to train_test_split.'\n...     (X_train, X_test, y_train, y_test) = output\n...     assert len(X_train) + len(X_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert len(y_train) + len(y_test) == len(df_new), 'The splits do not add up to the original data size.'\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert len(X_train) > 0 and len(X_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n...     assert len(y_train) > 0 and len(y_test) > 0, 'Some of the splits are empty. Make sure you pass the correct values to train_test_split'\n>>> test_split_data()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_correct_X():\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         (X_train, X_test, y_train, y_test) = split_data(df_new)\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(X_train.columns == X_test.columns), 'The columns in X_train and X_test are not the same.'\n...     assert np.allclose(np.mean(X_train), np.mean(X_test), atol=0.01), 'The mean of every column is not the same in X_train and X_test.'\n...     assert np.all((X_train >= 0) & (X_train <= 1)), 'X_train has values that are not between 0 and 1.'\n...     assert np.all((X_test >= 0) & (X_test <= 1)), 'X_test has values that are not between 0 and 1.'\n...     assert np.all((np.mean(X_train) >= 0) & (np.mean(X_train) <= 1)), 'X_train has columns with mean values not between 0 and 1.'\n...     assert np.all((np.mean(X_test) >= 0) & (np.mean(X_test) <= 1)), 'X_test has columns with mean values not between 0 and 1.'\n>>> def test_correct_y():\n...     splits = train_test_split(df_new.drop(columns='income'), df_new['income'], test_size=0.2, random_state=42)\n...     (X_train, X_test, y_train, y_test) = splits\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore', FutureWarning)\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...     assert np.all(y_train.isin([0, 1])), 'y_train has values that are not 0 or 1.'\n...     assert np.all(y_test.isin([0, 1])), 'y_test has values that are not 0 or 1.'\n>>> test_correct_X()\n>>> test_correct_y()\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_train_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     (X_train, X_test, y_train, y_test) = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore')\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...         model = train_model(X_train, y_train)\n...     return isinstance(model, LogisticRegression)\n>>> test_train_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> def test_evaluate_model():\n...     df_new = pd.read_csv('adult.csv').drop(columns=['native-country', 'fnlwgt']).dropna()\n...     (X_train, X_test, y_train, y_test) = split_data(df_new)\n...     with warnings.catch_warnings():\n...         warnings.simplefilter('ignore')\n...         (X_train, X_test, y_train, y_test) = preprocess_data(X_train, X_test, y_train, y_test)\n...         model = train_model(X_train, y_train)\n...         model = train_model(X_train, y_train)\n...         accuracy = evaluate_model(model, X_test, y_test)\n...     return bool(np.isclose(accuracy, 0.85, atol=0.1))\n>>> test_evaluate_model()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
